{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chc/anaconda3/envs/Segmentation/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/chc/anaconda3/envs/Segmentation/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/chc/anaconda3/envs/Segmentation/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/chc/anaconda3/envs/Segmentation/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/chc/anaconda3/envs/Segmentation/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/chc/anaconda3/envs/Segmentation/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/chc/anaconda3/envs/Segmentation/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/chc/anaconda3/envs/Segmentation/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/chc/anaconda3/envs/Segmentation/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/chc/anaconda3/envs/Segmentation/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/chc/anaconda3/envs/Segmentation/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/chc/anaconda3/envs/Segmentation/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import gdal\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import imageio\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from skimage import img_as_float\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import f1_score\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 6\n",
    "\n",
    "\n",
    "class BatchColors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_params = ['input_path', 'output_path(for model, images, etc)', 'currentModelPath', 'trainingInstances',\n",
    "                   'testing_instances', 'learningRate', 'weight_decay', 'batch_size', 'niter', 'reference_crop_size',\n",
    "                   'reference_stride_crop',\n",
    "                   'net_type[dilated_icpr_original|dilated_grsl|dilated_icpr_rate6|dilated_icpr_rate6_small|'\n",
    "                   'dilated_icpr_rate6_densely]',\n",
    "                   'distribution_type[single_fixed|multi_fixed|uniform|multinomial]', 'probValues',\n",
    "                   'update_type [acc|loss]', 'process [training|validate_test|generate_final_maps]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing individual Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"postdam\"\n",
    "input_path = \"/home/chc/Documents/CVML/dynamic-rs-segmentation/Postdam/\"\n",
    "output_path = \"/home/chc/Documents/CVML/dynamic-rs-segmentation/Output/\"\n",
    "former_model_path = \"/home/chc/Documents/CVML/dynamic-rs-segmentation/Model/\"\n",
    "trainingInstances = [\"2_10\",\"2_11\"]\n",
    "testing_instances = [\"2_12\"]\n",
    "lr_initial = 0.01\n",
    "weight_decay = 0.001\n",
    "batch_size = 128\n",
    "niter = 1000\n",
    "reference_crop_size = 50\n",
    "reference_stride_crop = 25\n",
    "net_type = \"dilated_icpr_original\"\n",
    "distribution_type = \"multinomial\"\n",
    "values = [45,55,65,75,85]\n",
    "update_type = \"acc\"\n",
    "process = \"training\"\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize resample_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'vaihingen':\n",
    "    resample_batch = 20\n",
    "elif dataset == 'postdam':\n",
    "    resample_batch = 10\n",
    "else:\n",
    "    print(\"Error! No dataset identified: \", dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create probability distribution array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_multinomial_probs(values, dif_prob=2):\n",
    "    interval_size = values[-1] - values[0] + 1\n",
    "\n",
    "    general_prob = 1.0 / float(interval_size)\n",
    "    max_prob = general_prob * dif_prob  # for values\n",
    "\n",
    "    probs = np.full(interval_size, (1.0 - max_prob * len(values)) / float(interval_size - len(values)))\n",
    "    for i in range(len(values)):\n",
    "        probs[values[i] - values[0]] = max_prob\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if distribution_type == 'multi_fixed':\n",
    "    patch_acc_loss = np.zeros(len(values), dtype=np.float32)\n",
    "    patch_occur = np.zeros(len(values), dtype=np.int32)\n",
    "    patch_chosen_values = np.zeros(len(values), dtype=np.int32)\n",
    "\n",
    "elif distribution_type == 'uniform' or distribution_type == 'multinomial':\n",
    "    patch_acc_loss = np.zeros(values[-1] - values[0] + 1, dtype=np.float32)\n",
    "    patch_occur = np.zeros(values[-1] - values[0] + 1, dtype=np.int32)\n",
    "    patch_chosen_values = np.zeros(values[-1] - values[0] + 1, dtype=np.int32)\n",
    "    probs = define_multinomial_probs(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path, instances, process, image_type='vaihingen'):\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for f in instances:\n",
    "        print(BatchColors.OKBLUE + 'Reading instance ' + str(f) + BatchColors.ENDC)\n",
    "        \n",
    "        if image_type == 'postdam':\n",
    "            \n",
    "            img_ndsm = img_as_float(imageio.imread(path + '1_DSM_normalisation/dsm_potsdam_0' + (\n",
    "                str(f) if int(f.split(\"_\")[1]) >= 10 else str(f.split(\"_\")[0]) + '_0' + str(\n",
    "                    f.split(\"_\")[1])) + '_normalized_lastools.jpg'))\n",
    "            \n",
    "#             print(type(img_ndsm))\n",
    "#             plt.imshow(img_ndsm, interpolation='nearest')\n",
    "#             plt.show()\n",
    "            \n",
    "            if len(img_ndsm) != len(img_ndsm[0]):\n",
    "                new_columns = np.zeros([len(img_ndsm), 1], dtype=type(img_ndsm[0, 0]))\n",
    "                img_ndsm = np.append(img_ndsm, new_columns, axis=1)\n",
    "            \n",
    "            img_ndsm = np.reshape(img_ndsm, (len(img_ndsm), len(img_ndsm[0]), 1))\n",
    "                        \n",
    "            ds = gdal.Open(path + '4_Ortho_RGBIR/top_potsdam_' + str(f) + '_RGBIR.tif')\n",
    "            img_rgb = np.empty([ds.RasterXSize, ds.RasterYSize, ds.RasterCount], dtype=np.float64)\n",
    "#             print(ds.RasterCount)\n",
    "#             print(img_rgb.shape)\n",
    "#             plt.imshow(img_ndsm[:,:,0], interpolation='nearest')\n",
    "#             plt.show()\n",
    "            \n",
    "            for band in range(1, ds.RasterCount + 1):\n",
    "                img_rgb[:, :, band - 1] = img_as_float(np.array(ds.GetRasterBand(band).ReadAsArray()))\n",
    "\n",
    "            if process == 'validate_test':\n",
    "                img_label = imageio.imread(path + 'gts_eroded_encoding/top_potsdam_' + str(f) +\n",
    "                                              '_label_noBoundary.tif')\n",
    "            elif process == 'training' or process == 'crf':\n",
    "                img_label = imageio.imread(path + '5_Labels_all/top_potsdam_' + str(f) + '_label.tif')\n",
    "        \n",
    "\n",
    "        full_img = np.concatenate((img_rgb, img_ndsm), axis=2)\n",
    "#         print(full_img.shape)\n",
    "#         plt.imshow(img_ndsm[:,:,0], interpolation='nearest')\n",
    "#         plt.show()\n",
    "\n",
    "        images.append(full_img)\n",
    "        if process == 'validate_test' or process == 'training' or process == 'crf':\n",
    "            masks.append(img_label)\n",
    "\n",
    "    return np.asarray(images), np.asarray(masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mReading images...\u001b[0m\n",
      "\u001b[94mReading instance 2_10\u001b[0m\n",
      "\u001b[94mReading instance 2_11\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(BatchColors.WARNING + 'Reading images...' + BatchColors.ENDC)\n",
    "training_data, training_labels = load_images(input_path, trainingInstances, process, image_type=dataset)\n",
    "print(\"Training Data Loaded ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mReading instance 2_12\u001b[0m\n",
      "Testing Data Loaded ...\n"
     ]
    }
   ],
   "source": [
    "testing_data, testing_labels = load_images(input_path, testing_instances, process, image_type=dataset)\n",
    "print(\"Testing Data Loaded ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distributions_over_classes(labels, crop_size, stride_crop):\n",
    "    classes = [[[] for i in range(0)] for i in range(NUM_CLASSES)]\n",
    "    print(len(classes))\n",
    "    print(len(labels))\n",
    "    print(\"------------------\")\n",
    "    for k in range(len(labels)):\n",
    "        w, h, channels = labels[k].shape\n",
    "\n",
    "        for i in range(0, w, stride_crop):\n",
    "            for j in range(0, h, stride_crop):\n",
    "                cur_map = k\n",
    "                cur_x = i\n",
    "                cur_y = j\n",
    "                patch_class = labels[cur_map][cur_x:cur_x + crop_size, cur_y:cur_y + crop_size]\n",
    "\n",
    "                if len(patch_class) != crop_size and len(patch_class[0]) != crop_size:\n",
    "                    cur_x = cur_x - (crop_size - len(patch_class))\n",
    "                    cur_y = cur_y - (crop_size - len(patch_class[0]))\n",
    "                    patch_class = labels[cur_map][cur_x:cur_x + crop_size, cur_y:cur_y + crop_size]\n",
    "                elif len(patch_class) != crop_size:\n",
    "                    cur_x = cur_x - (crop_size - len(patch_class))\n",
    "                    patch_class = labels[cur_map][cur_x:cur_x + crop_size, cur_y:cur_y + crop_size]\n",
    "                elif len(patch_class[0]) != crop_size:\n",
    "                    cur_y = cur_y - (crop_size - len(patch_class[0]))\n",
    "                    patch_class = labels[cur_map][cur_x:cur_x + crop_size, cur_y:cur_y + crop_size]\n",
    "\n",
    "                if patch_class.shape == (crop_size, crop_size, channels):\n",
    "                    count = np.bincount(patch_class.astype(int).flatten())\n",
    "                    # print(count)\n",
    "                    # print(len(count))\n",
    "                    # print(int(np.argmax(count)))\n",
    "                    classes[int(np.argmax(count))].append((cur_map, cur_x, cur_y))\n",
    "                else:\n",
    "                    print(BatchColors.FAIL + \"Error create_distributions_over_classes: Current patch size is \" + str(\n",
    "                        len(patch_class)) + \"x\" + str(len(patch_class[0])) + BatchColors.ENDC)\n",
    "                    return\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        print(BatchColors.OKBLUE + 'Class ' + str(i + 1) + ' has length ' + str(len(classes[i])) + BatchColors.ENDC)\n",
    "\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mCreating TRAINING class distribution...\u001b[0m\n",
      "6\n",
      "2\n",
      "------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-35c94f8fa876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchColors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARNING\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Creating TRAINING class distribution...'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mBatchColors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENDC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m training_class_distribution = create_distributions_over_classes(training_labels, crop_size=reference_crop_size,\n\u001b[0;32m----> 3\u001b[0;31m                                                                         stride_crop=reference_stride_crop)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-5cbd922b4da6>\u001b[0m in \u001b[0;36mcreate_distributions_over_classes\u001b[0;34m(labels, crop_size, stride_crop)\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;31m# print(len(count))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0;31m# print(int(np.argmax(count)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                     \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     print(BatchColors.FAIL + \"Error create_distributions_over_classes: Current patch size is \" + str(\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(BatchColors.WARNING + 'Creating TRAINING class distribution...' + BatchColors.ENDC)\n",
    "training_class_distribution = create_distributions_over_classes(training_labels, crop_size=reference_crop_size,\n",
    "                                                                        stride_crop=reference_stride_crop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
